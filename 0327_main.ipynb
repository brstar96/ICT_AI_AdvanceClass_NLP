{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이 코드에서는 가중치를 적용해 IR(Information Retrieval)을 수행하는 방법에 대해 알아봅니다. (TF, IDF)\n",
    "collection = [\n",
    "    ('Document1', 'This is a sample'),\n",
    "    ('Document2', 'This is another sample')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-memory (Hash Key 값)\n",
    "# 전체 색인어 목록(Dictionary)\n",
    "# {단어1:포스팅위치, 단어2:포스팅위치, ...}\n",
    "globalLexicon = dict()\n",
    "\n",
    "# 전체 문서 목록(Dictionary)\n",
    "# [0:문서1, 1:문서2, ...]\n",
    "globalDocument = list()\n",
    "\n",
    "# disk\n",
    "# 사전에 있는 색인어 중, 어느 문서에서, 몇 번 나타났는지\n",
    "# [(단어 idx, 문서 idx, 빈도, 다음주소), ...]\n",
    "# [0:Tuple(lexiconIdx, documentIdx, freq, 다음포스팅위치-fptr)]\n",
    "# 메모리 X, File OK\n",
    "globalPosting = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (docName, docContent) in collection:\n",
    "    # Pointer 대체용, Key, Document 이름은 절대로 겹치지 않는다는 가정. \n",
    "    docIdx = len(globalDocument)\n",
    "    globalDocument.append(docName)\n",
    "    \n",
    "    # {단어idx:빈도, 단어idx:빈도, ...}\n",
    "    localPosting = dict()\n",
    "    \n",
    "    # Local 작업\n",
    "    for term in docContent.lower().split():\n",
    "        # Local에 대해서 수행한 후 없으면 새 posting으로 추가\n",
    "        if term not in localPosting.keys():\n",
    "            localPosting[term] = 1 # dict\n",
    "        # 있으면, 빈도 증가\n",
    "        else:\n",
    "            localPosting[term] += 1\n",
    "     \n",
    "    # Global Marge\n",
    "    # fp -> struct(단어, 빈도) (localPosting)\n",
    "    for indexTerm, termFreq in localPosting.items(): # indexTerm : str,termFreq : int \n",
    "        if indexTerm not in globalLexicon.keys(): \n",
    "            lexiconIdx = len(globalLexicon)\n",
    "            postingIdx = len(globalPosting) # fseek\n",
    "            postingData = (lexiconIdx, docIdx, termFreq, -1)\n",
    "            globalPosting.append(postingData)\n",
    "            globalLexicon[indexTerm] = postingIdx # globalPosting 위치(ptr:idx)\n",
    "        else: # 기존 단어의 idx 가져오기\n",
    "            lexiconIdx = list(globalLexicon.keys()).index(indexTerm)\n",
    "            postingIdx = len(globalPosting)\n",
    "            beforeIdx = globalLexicon[indexTerm]\n",
    "            postingData = (lexiconIdx, docIdx, termFreq, beforeIdx)\n",
    "            globalPosting.append(postingData)\n",
    "            globalLexicon[indexTerm] = postingIdx\n",
    "            \n",
    "#     print(localPosting)\n",
    "# print(globalDocument)\n",
    "\n",
    "#         if term not in globalLexicon.keys():\n",
    "#             lexiconIdx = len(globalLexicon) 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'this': 4, 'is': 5, 'a': 2, 'sample': 7, 'another': 6},\n ['Document1', 'Document2'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalLexicon, globalDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 1, -1),\n (1, 0, 1, -1),\n (2, 0, 1, -1),\n (3, 0, 1, -1),\n (0, 1, 1, 0),\n (1, 1, 1, 1),\n (4, 1, 1, -1),\n (3, 1, 1, 3)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalPosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n  DocName:Document2 - TermFreq:1 - Next:0\n  DocName:Document1 - TermFreq:1 - Next:-1\n\nis\n  DocName:Document2 - TermFreq:1 - Next:1\n  DocName:Document1 - TermFreq:1 - Next:-1\n\na\n  DocName:Document1 - TermFreq:1 - Next:-1\n\nsample\n  DocName:Document2 - TermFreq:1 - Next:3\n  DocName:Document1 - TermFreq:1 - Next:-1\n\nanother\n  DocName:Document2 - TermFreq:1 - Next:-1\n\n"
     ]
    }
   ],
   "source": [
    "for indexTerm, postingIdx in globalLexicon.items():\n",
    "    # indexTerm:단어: postingIdx:위치, ...\n",
    "    print(indexTerm)\n",
    "    \n",
    "    while True: # Posting Next:-1\n",
    "        if postingIdx == -1:\n",
    "            break\n",
    "            \n",
    "        postingData = globalPosting[postingIdx]\n",
    "        print('  DocName:{0} - TermFreq:{1} - Next:{2}'.format(globalDocument[postingData[1]], postingData[2], postingData[3]))\n",
    "        postingIdx = postingData[3]\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 1, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalPosting[globalLexicon['sample']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0, 1, -1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalPosting[globalPosting[globalLexicon['sample']][3]]   # 다음 주소가 \"-1\" 일때 까지 반복해서 찾음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = [\n",
    "    ('Document1', 'This is a a a a a a a a a a sample'),\n",
    "    ('Document2', 'This is a sample'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "# TF를 수행하는 네 가지 방법 정의\n",
    "def binaryTF(freq):\n",
    "    if freq > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def rawTF(freq):\n",
    "    return freq\n",
    "\n",
    "def basicTF(freq, totalFreq):\n",
    "    return freq/totalFreq\n",
    "\n",
    "def logTF(freq):\n",
    "    if freq > 0:\n",
    "        return 1+log10(freq)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def doubleNormalTF(K, freq, maxFreq): \n",
    "    return K + ((1-K) * (freq/maxFreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\nthis\n1. Binary:1\n2. Raw:1\n3. Basic:0.07692307692307693\n4. Log:1.0\n5. DoubleNormalization:0.1\n6. DoubleNormalization:0.55\n\nis\n1. Binary:1\n2. Raw:1\n3. Basic:0.07692307692307693\n4. Log:1.0\n5. DoubleNormalization:0.1\n6. DoubleNormalization:0.55\n\na\n1. Binary:1\n2. Raw:10\n3. Basic:0.7692307692307693\n4. Log:2.0\n5. DoubleNormalization:1.0\n6. DoubleNormalization:1.0\n\nsample\n1. Binary:1\n2. Raw:1\n3. Basic:0.07692307692307693\n4. Log:1.0\n5. DoubleNormalization:0.1\n6. DoubleNormalization:0.55\n\n{'this': 1, 'is': 1, 'a': 10, 'sample': 1}\n\n-----------------------------------\nthis\n1. Binary:1\n2. Raw:1\n3. Basic:0.25\n4. Log:1.0\n5. DoubleNormalization:1.0\n6. DoubleNormalization:1.0\n\nis\n1. Binary:1\n2. Raw:1\n3. Basic:0.25\n4. Log:1.0\n5. DoubleNormalization:1.0\n6. DoubleNormalization:1.0\n\na\n1. Binary:1\n2. Raw:1\n3. Basic:0.25\n4. Log:1.0\n5. DoubleNormalization:1.0\n6. DoubleNormalization:1.0\n\nsample\n1. Binary:1\n2. Raw:1\n3. Basic:0.25\n4. Log:1.0\n5. DoubleNormalization:1.0\n6. DoubleNormalization:1.0\n\n{'this': 1, 'is': 1, 'a': 1, 'sample': 1}\n\n"
     ]
    }
   ],
   "source": [
    "for (docName, docContent) in collection:\n",
    "    localPosting = dict()\n",
    "    \n",
    "    for term in docContent.lower().split():\n",
    "        if term not in localPosting.keys():\n",
    "            localPosting[term] = 1\n",
    "        else:\n",
    "            localPosting[term] += 1\n",
    "    \n",
    "    # localPosting => {단어:빈도, 단어:빈도, ...}\n",
    "    \n",
    "    maxFreq = max(localPosting.values())\n",
    "    totalCount = sum(localPosting.values())\n",
    "    \n",
    "    print('-----------------------------------')\n",
    "    \n",
    "    for term, freq in localPosting.items():\n",
    "        print(term)\n",
    "        print('1. Binary:{0}'.format(binaryTF(freq)))\n",
    "        print('2. Raw:{0}'.format(rawTF(freq)))\n",
    "        print('3. Basic:{0}'.format(basicTF(freq, totalCount)))\n",
    "        print('4. Log:{0}'.format(logTF(freq)))\n",
    "        print('5. DoubleNormalization:{0}'.format(doubleNormalTF(0, freq, maxFreq)))\n",
    "        print('6. DoubleNormalization:{0}'.format(doubleNormalTF(0.5, freq, maxFreq)))\n",
    "        print()\n",
    "    \n",
    "    print(localPosting)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = [\n",
    "    ('Document1', 'This a a a a a a a a a a  sample'),\n",
    "    ('Document2', 'This is a sample'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF(Inverse Document Frequency)를 수행하기 위한 네 가지 방법 정의\n",
    "def unaryIDF():\n",
    "    return 1\n",
    "\n",
    "def basicIDF(N, df):\n",
    "    return log10(N/df)\n",
    "\n",
    "def smoothigIDF(N, df):\n",
    "    return log10((N+1)/df)\n",
    "\n",
    "def probabilityIDF(N, df):\n",
    "    return log10((N-df+1)/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n1. UnaryIDF: 1\n2. BasicIDF: 0.0\n3. SmoothigIDF: 0.17609125905568124\n4. ProbabilityIDF: -0.3010299956639812\n\nis\n1. UnaryIDF: 1\n2. BasicIDF: 0.0\n3. SmoothigIDF: 0.17609125905568124\n4. ProbabilityIDF: -0.3010299956639812\n\na\n1. UnaryIDF: 1\n2. BasicIDF: 0.3010299956639812\n3. SmoothigIDF: 0.47712125471966244\n4. ProbabilityIDF: 0.3010299956639812\n\nsample\n1. UnaryIDF: 1\n2. BasicIDF: 0.0\n3. SmoothigIDF: 0.17609125905568124\n4. ProbabilityIDF: -0.3010299956639812\n\nanother\n1. UnaryIDF: 1\n2. BasicIDF: 0.3010299956639812\n3. SmoothigIDF: 0.47712125471966244\n4. ProbabilityIDF: 0.3010299956639812\n\n"
     ]
    }
   ],
   "source": [
    "N = len(collection)\n",
    "\n",
    "for term, ptr in globalLexicon.items():\n",
    "    # term:단어, ptr:위치, ...\n",
    "    df = 0\n",
    "    \n",
    "    while True:    # ptr Next: -1\n",
    "        if ptr == -1:\n",
    "            break\n",
    "        \n",
    "        df += 1\n",
    "        postingData = globalPosting[ptr]\n",
    "        ptr = postingData[3]\n",
    "    \n",
    "    print(term)\n",
    "    print('1. UnaryIDF: {0}'.format(unaryIDF()))\n",
    "    print('2. BasicIDF: {0}'.format(basicIDF(N,df)))\n",
    "    print('3. SmoothigIDF: {0}'.format(smoothigIDF(N,df)))\n",
    "    print('4. ProbabilityIDF: {0}'.format(probabilityIDF(N,df)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
